---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r echo=FALSE, out.width= 800, out.height= 200}
knitr::include_graphics('imgs/credito.jpg')
```



# Análise de Crédito

<!-- badges: start -->
<!-- badges: end -->
#### O objetivo desse estudo consiste na análise dos dados históricos de empréstimos e na elaboração de um modelo de classificação para concessão de crédito.  

#### Os dados foram coletados no site: https://www.kaggle.com/zaurbegiev/my-dataset e armazenados no banco de dados SQL Server 2017. 

##### Etapas: 
##### 1 - Análise exploratória do conjunto de dados. 


##### Pacotes utilizados na análise
```{r message=FALSE}
library(odbc)
library(tidyverse)
library(questionr)
library(knitr)
library(patchwork)

```



```{r include=FALSE}
con <- dbConnect(odbc(),
                 Driver = "ODBC Driver 17 for SQL Server",
                 Server = "VINIPC",
                 Database = "projetobank",
                 UID = "sa",
                 PWD = '2510@vini',
                 Port = 8070)

```


##### Estabelecendo conexão com o banco de dados SQL Server 2017, para extração/leitura dos dados. 

```{r eval = FALSE}
con <- dbConnect(odbc(),
                 Driver = "ODBC Driver 17 for SQL Server",
                 Server = "##",
                 Database = "projetobank",
                 UID = "##",
                 PWD = '##',
                 Port ='##')
```


##### Carregando os dados do banco pro R. 

```{r}

df_bank_train <- dbGetQuery(con, 'SELECT * FROM bank_train')

```

##### Ajustando os nomes das variáveis
```{r}

df_bank_train <-  janitor::clean_names(df_bank_train)

```

##### Info dos dados:
##### O o dataframe tem 100.514 observações e um conjunto de 19 variáveis. 
##### A variável target para esse estudo será (loan_status). 
```{r}

glimpse(df_bank_train)
```

##### Existem dados faltantes no conjunto de dados? 
```{r}
freq.na(df_bank_train)

```

##### Como a maior parte das variáveis apresenta 514 dados faltantes, verifiquei se são linhas inteiras de NA. 
##### Visto que, o teste resultou em um conjunto de dados faltantes uniformes, optei pelo descarte. 
##### A tabela abaixo representa o novo conjunto de dados.   
```{r, include=FALSE}
questionr::freq.na(df_bank_train %>% 
  filter(is.na(loan_id)))


```

 

```{r}
df_bank_train <- df_bank_train %>% 
                 filter(!is.na(loan_id))

freq.na(df_bank_train)
```


##### Após esse filtro ficamos com dados ausentes nas variáveis: 
###### 53% months_since_last_delinquent (Meses desde a última inadimplência)
###### 19% credit_score (score de crédito)
###### 19% annual_income (renda anual)
###### 204 obs. bankruptcies (falência)
###### 10 obs. tax_liens (linhas de impostos)
###### 2 obs. maximum_open_credit (abertura máxima de crédito)


##### Tratamento das varáveis faltantes: 

##### 204 obs. bankruptcies (falência)
###### Conforme análise da tabela de frequência relativa, foi verificado que a distribuiçao % se comporta como nas faixas [0,1,2,3,4,5] entre (22,74% - 28,57%) de Charge Off e (77.26 % - 71.43 %). Devido a relação com a variável target e ao baixo número de observações, entendo que não vai influenciar no resultado do modelo a imputação pela faixa com mais observações da variável bankruptcies (0).  

```{r}
  df_bank_train %>%
  group_by(bankruptcies, loan_status) %>% 
  summarise(qnt = n()) %>% 
  complete(bankruptcies, fill = list(n = 0)) %>% 
  group_by(bankruptcies) %>% 
  mutate(freq = paste(round(qnt / sum(qnt),4)*100,'%'))

```

```{r}
  df_bank_train$bankruptcies <- df_bank_train$bankruptcies %>% 
  coalesce(0)
```





##### 2 obs. maximum_open_credit (abertura máxima de crédito)

###### Optei por preencher com a mediana dos dados. 
###### Ao tirar algumas estatísticas e visualizações dessa váriável fica claro o quanto assímetrico é a distribuição. 
###### A média é muito maior que a mediana, visualmente percebemos uma curva assimétrica a direita, com amplitude (0 - 1.539.737.892). 

```{r}
  print(paste('Média', round(mean(df_bank_train$maximum_open_credit, na.rm = TRUE),2),sep = ': '))
  print(paste('Mediana',round(median(df_bank_train$maximum_open_credit, na.rm = TRUE),2),sep = ': '))
  print(paste('Desvio Padrão',round(sd(df_bank_train$maximum_open_credit, na.rm = TRUE),2),sep = ': '))
  print(paste('Máximo',round(max(df_bank_train$maximum_open_credit, na.rm = TRUE),2),sep = ': '))
  print(paste('Mínimo',round(min(df_bank_train$maximum_open_credit, na.rm = TRUE),2),sep = ': '))
```

##### O gráfico abaixo mostra a curva de densidade da váriavel e de um possível ajuste dos dados. 

```{r message=FALSE, warning=FALSE}
a <- df_bank_train %>% 
    ggplot() +
      aes(x = maximum_open_credit) +
    geom_density(adjust = 2.8, fill = "#114642") +
      scale_x_continuous(trans = "log") +
       labs(
      x = "Valores (Log)",
      y = "Densidade",
      title = "Abertura de Crédito Máximo (Log)"
      ) +
    theme_bw()

 b <-  df_bank_train %>% 
    ggplot() +
      aes(x = maximum_open_credit) +
    geom_density(adjust = 2.8, fill = "#114642") +
      labs(
      x = "Valores",
      y = "Densidade",
      title = "Abertura de Crédito Máximo "
      ) +
    theme_bw()
b+a  

```






